{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d45989-3e2a-4430-9c86-d80845c035c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script started/restarted: 2025-04-18 23:54:18\n",
      "Found SuperGlue-pytorch repository at: /home/jain/Desktop/IITK/Project_EE798T/SuperGlue-pytorch\n",
      "Successfully imported SuperGlue class from repository.\n",
      "Using device: cuda\n",
      "SIFT detector created successfully (max features = 512). OpenCV version: 4.11.0\n",
      "SIFT detector created successfully. OpenCV version: 4.11.0\n",
      "\n",
      "Using SuperGlue config:\n",
      "  'descriptor_dim': 128\n",
      "  'weights_path': SuperGlue-pytorch/models/weights/superglue_outdoor.pth\n",
      "  'keypoint_encoder': [32, 64, 128]\n",
      "  'GNN_layers': ['self', 'cross', 'self']... (x18)\n",
      "  'sinkhorn_iterations': 100\n",
      "  'match_threshold': 0.2\n",
      "\n",
      "SuperGlue weights file found at: /home/jain/Desktop/IITK/Project_EE798T/SuperGlue-pytorch/models/weights/superglue_outdoor.pth\n",
      "(Note: These weights ('superglue_outdoor.pth') were likely trained on SuperPoint features, not SIFT.\n",
      "       Matching performance may differ from the original SuperPoint results.)\n",
      "\n",
      "Cell 1 Setup Complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup (SIFT Version - Corrected Weights Path)\n",
    "\n",
    "import os\n",
    "import re\n",
    "import cv2 # Use cv2 directly\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt # Usually needed later for plots if enabled\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import math\n",
    "import time # For timing cell later\n",
    "import random # For timing cell later\n",
    "import traceback # For detailed errors later\n",
    "\n",
    "print(f\"Script started/restarted: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Add the cloned repository directory to Python path\n",
    "# Assumes the repo is cloned in the same directory as the notebook\n",
    "superglue_sift_repo_path = Path('./SuperGlue-pytorch')\n",
    "if not superglue_sift_repo_path.is_dir():\n",
    "    # Try to give a more helpful error message\n",
    "    print(f\"ERROR: Repository directory not found at '{superglue_sift_repo_path.resolve()}'\")\n",
    "    print(\"Please ensure you have cloned 'https://github.com/yingxin-jia/SuperGlue-pytorch'\")\n",
    "    print(\"into the same directory where this notebook is located,\")\n",
    "    print(\"or update the 'superglue_sift_repo_path' variable.\")\n",
    "    # Raise error to stop execution if repo not found\n",
    "    raise FileNotFoundError(f\"Repository directory not found at {superglue_sift_repo_path}\")\n",
    "else:\n",
    "    print(f\"Found SuperGlue-pytorch repository at: {superglue_sift_repo_path.resolve()}\")\n",
    "    sys.path.append(str(superglue_sift_repo_path))\n",
    "\n",
    "# Import SuperGlue model components from THIS repository\n",
    "# *** NOTE: You MAY need to adjust the exact import path/class name based on the repo ***\n",
    "try:\n",
    "    from models.superglue import SuperGlue # Common structure, verify if needed\n",
    "    print(\"Successfully imported SuperGlue class from repository.\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR: Failed to import SuperGlue class from '{superglue_sift_repo_path / 'models/superglue.py'}'\")\n",
    "    print(f\"       Check the file structure and class name in the repository.\")\n",
    "    print(f\"       Error details: {e}\")\n",
    "    # Raise error or allow proceeding but model loading will fail\n",
    "    raise e # Stop execution if import fails\n",
    "\n",
    "# --- Configuration ---\n",
    "# Setup device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# SIFT Configuration (OpenCV)\n",
    "# Need opencv-contrib-python installed for SIFT\n",
    "try:\n",
    "    NUM_SIFT_FEATURES = 512 # Limit features (adjust as needed, e.g., 2048, 4096)\n",
    "    sift = cv2.SIFT_create(nfeatures=NUM_SIFT_FEATURES)\n",
    "    print(f\"SIFT detector created successfully (max features = {NUM_SIFT_FEATURES}). OpenCV version: {cv2.__version__}\")\n",
    "    print(f\"SIFT detector created successfully. OpenCV version: {cv2.__version__}\")\n",
    "    # Example: You can customize SIFT parameters here if needed\n",
    "    # sift = cv2.SIFT_create(nfeatures=0, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6)\n",
    "except AttributeError:\n",
    "    print(\"ERROR: cv2.SIFT_create() not found.\")\n",
    "    print(\"       This usually means you don't have 'opencv-contrib-python' installed.\")\n",
    "    print(\"       Please install it: pip install opencv-contrib-python\")\n",
    "    sift = None # Set to None to handle gracefully later\n",
    "    raise AttributeError(\"cv2.SIFT_create() not found. Install opencv-contrib-python.\")\n",
    "\n",
    "# SuperGlue Configuration (for this specific repo)\n",
    "# Using the weights path you provided\n",
    "superglue_config = {\n",
    "    'descriptor_dim': 128, # SIFT descriptor dimension is 128\n",
    "    # --- Using the weights path you specified ---\n",
    "    'weights_path': str(superglue_sift_repo_path / 'models/weights/superglue_outdoor.pth'),\n",
    "    # ------------------------------------------\n",
    "    # --- These parameters below are examples - VERIFY or REMOVE if not needed by this repo's SuperGlue class ---\n",
    "    'keypoint_encoder': [32, 64, 128], # Example network layer sizes\n",
    "    'GNN_layers': ['self', 'cross'] * 9, # Example GNN structure\n",
    "    'sinkhorn_iterations': 100, # Example Sinkhorn iterations\n",
    "    'match_threshold': 0.2, # Example matching threshold (tune later)\n",
    "    # --- End of Example Parameters ---\n",
    "}\n",
    "print(f\"\\nUsing SuperGlue config:\")\n",
    "# Print config nicely\n",
    "for key, value in superglue_config.items():\n",
    "    # Shorten long GNN layer list for printing\n",
    "    if key == 'GNN_layers' and isinstance(value, list) and len(value) > 6:\n",
    "         print(f\"  '{key}': {value[:3]}... (x{len(value)})\")\n",
    "    else:\n",
    "         print(f\"  '{key}': {value}\")\n",
    "\n",
    "# Check if the specified weights file exists\n",
    "weights_file = Path(superglue_config['weights_path'])\n",
    "if not weights_file.is_file():\n",
    "     print(f\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "     print(f\"WARNING: Specified SuperGlue weights file NOT FOUND at:\")\n",
    "     print(f\"         '{weights_file.resolve()}'\")\n",
    "     print(f\"         Please ensure the file exists at this location.\")\n",
    "     print(f\"         Model loading in Cell 5 will likely FAIL.\")\n",
    "     print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")\n",
    "else:\n",
    "    print(f\"\\nSuperGlue weights file found at: {weights_file.resolve()}\")\n",
    "    # Add note about potential mismatch between weights and features\n",
    "    if \"superglue_outdoor\" in weights_file.name or \"superglue_indoor\" in weights_file.name:\n",
    "         print(\"(Note: These weights ('superglue_outdoor.pth') were likely trained on SuperPoint features, not SIFT.\")\n",
    "         print(\"       Matching performance may differ from the original SuperPoint results.)\")\n",
    "\n",
    "\n",
    "# --- Constants ---\n",
    "QUERY_DIR = Path('./extended_dataset/camera image')\n",
    "REF_DIR = Path('./extended_dataset/reference image')\n",
    "REFERENCE_IMAGE_SIZE = (1000, 1000) # Keep assumption or load an image to check\n",
    "VIZ_COUNT = 5 # Default number of results to visualize later\n",
    "\n",
    "# Check if data directories exist early\n",
    "if not QUERY_DIR.is_dir():\n",
    "     print(f\"\\nWARNING: Query directory NOT FOUND at '{QUERY_DIR.resolve()}'\")\n",
    "if not REF_DIR.is_dir():\n",
    "     print(f\"\\nWARNING: Reference directory NOT FOUND at '{REF_DIR.resolve()}'\")\n",
    "\n",
    "print(\"\\nCell 1 Setup Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88018255-d3a5-4fc6-a77e-5c8a905bf4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Function to Parse Filename (No Changes Needed)\n",
    "# Same function as before - parses ground truth from filename\n",
    "\n",
    "def parse_filename(filename):\n",
    "    \"\"\"\n",
    "    Parses the filename to extract ground truth coordinates and angle.\n",
    "    Filename format: (ignore)_(x,y)_angle_(ignore).png\n",
    "    Coordinates: (x, y) relative to reference center. +x down, +y right.\n",
    "    Angle: Anti-clockwise rotation degrees (0-360).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Using Path object's stem attribute is slightly cleaner\n",
    "        fname_stem = filename.stem\n",
    "        parts = fname_stem.split('_')\n",
    "        if len(parts) < 3:\n",
    "            # Handle cases like '.DS_Store' or other unexpected filenames gracefully\n",
    "            if not fname_stem.startswith('.'):\n",
    "                 print(f\"Warning: Skipping poorly formatted file (less than 3 parts): {filename.name}\")\n",
    "            return None\n",
    "\n",
    "        gt_x, gt_y, gt_angle = None, None, None\n",
    "        coord_part_index, angle_part_index = -1, -1\n",
    "\n",
    "        # Find coordinate part (flexible parsing)\n",
    "        for i in range(1, len(parts) -1):\n",
    "            part = parts[i]\n",
    "            # Try regex for (float,float)\n",
    "            coord_match = re.search(r'\\((-?\\d+\\.?\\d*),(-?\\d+\\.?\\d*)\\)', part)\n",
    "            if coord_match:\n",
    "                gt_x = float(coord_match.group(1))\n",
    "                gt_y = float(coord_match.group(2))\n",
    "                coord_part_index = i\n",
    "                break\n",
    "            # Try splitting by comma if no parentheses\n",
    "            coord_parts = part.split(',')\n",
    "            if len(coord_parts) == 2:\n",
    "                 try:\n",
    "                     gt_x_try = float(coord_parts[0])\n",
    "                     gt_y_try = float(coord_parts[1])\n",
    "                     # Basic sanity check for reasonable coordinate values if needed\n",
    "                     # if -1000 < gt_x_try < 1000 and -1000 < gt_y_try < 1000:\n",
    "                     gt_x = gt_x_try\n",
    "                     gt_y = gt_y_try\n",
    "                     coord_part_index = i\n",
    "                     break\n",
    "                 except ValueError:\n",
    "                     continue # Not a float pair\n",
    "\n",
    "        if gt_x is None:\n",
    "             print(f\"Warning: Could not parse coordinate part in file: {filename.name}\")\n",
    "             return None\n",
    "\n",
    "        # Find angle part (usually follows coordinate part)\n",
    "        # Start searching from the part *after* the identified coordinate part\n",
    "        search_start_index = coord_part_index + 1\n",
    "        for i in range(search_start_index, len(parts) -1):\n",
    "             try:\n",
    "                  gt_angle = float(parts[i])\n",
    "                  angle_part_index = i\n",
    "                  break # Found the first float after coordinates\n",
    "             except ValueError:\n",
    "                  continue\n",
    "\n",
    "        if gt_angle is None:\n",
    "            # Fallback: Search all parts between first and last underscore if not found after coords\n",
    "             for i in range(1, len(parts) - 1):\n",
    "                  if i == coord_part_index: continue # Skip the coord part itself\n",
    "                  try:\n",
    "                      gt_angle = float(parts[i])\n",
    "                      angle_part_index = i\n",
    "                      break\n",
    "                  except ValueError:\n",
    "                      continue\n",
    "\n",
    "        if gt_angle is None:\n",
    "             print(f\"Warning: Could not parse angle part in file: {filename.name}\")\n",
    "             return None\n",
    "\n",
    "        # Validate angle range (0-360) - allow slight tolerance\n",
    "        if not (-1e-9 <= gt_angle <= 360 + 1e-9):\n",
    "             print(f\"Warning: Angle {gt_angle:.4f} out of range [0, 360] in file: {filename.name}. Adjusting.\")\n",
    "             gt_angle = gt_angle % 360\n",
    "             if gt_angle < 0: gt_angle += 360 # Ensure positive\n",
    "\n",
    "        # Optional: Validate coordinate ranges based on reference size if needed\n",
    "        max_coord = REFERENCE_IMAGE_SIZE[0] / 2\n",
    "        if not (-max_coord <= gt_x <= max_coord and -max_coord <= gt_y <= max_coord):\n",
    "             print(f\"Warning: Coords ({gt_x}, {gt_y}) seem out of expected range [+/-{max_coord}] for {filename.name}\")\n",
    "             # Decide whether to return None or proceed\n",
    "\n",
    "        return {'x': gt_x, 'y': gt_y, 'angle': gt_angle}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing filename {filename.name}: {e}\")\n",
    "        # import traceback\n",
    "        # traceback.print_exc() # Uncomment for detailed traceback during debugging\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bd73f5e-ffe8-4395-b8e3-06e49422c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Function to Estimate Transformation (No Changes Needed)\n",
    "# This function works on keypoint coordinates (Nx2 numpy arrays) and matches,\n",
    "# regardless of whether they came from SIFT or SuperPoint.\n",
    "\n",
    "def estimate_transform(mkpts0, mkpts1):\n",
    "    \"\"\"\n",
    "    Estimates rotation and translation from matched keypoint coordinates using RANSAC.\n",
    "    Assumes mkpts0 and mkpts1 are Nx2 numpy arrays of corresponding points.\n",
    "\n",
    "    Returns:\n",
    "        - M: 2x3 Affine transformation matrix (or None if failed)\n",
    "        - angle_deg: Estimated rotation in degrees (anti-clockwise, 0-360)\n",
    "        - trans_px: Estimated translation (tx, ty) in pixels (relative to top-left)\n",
    "        - mask: RANSAC inlier mask\n",
    "    \"\"\"\n",
    "    if mkpts0 is None or mkpts1 is None or len(mkpts0) == 0 or len(mkpts1) == 0:\n",
    "        # print(\"Warning: estimate_transform received empty keypoints.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    min_req_matches = 3 # Minimum points for estimateAffine2D RANSAC\n",
    "    if mkpts0.shape[0] < min_req_matches:\n",
    "        # print(f\"Warning: Not enough matches ({mkpts0.shape[0]}) for RANSAC.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Ensure input arrays are float32, as expected by estimateAffine2D\n",
    "    mkpts0 = np.float32(mkpts0)\n",
    "    mkpts1 = np.float32(mkpts1)\n",
    "\n",
    "    # Use cv2.estimateAffine2D for rotation, translation, and scale robustness\n",
    "    M, mask = cv2.estimateAffine2D(mkpts0, mkpts1, method=cv2.RANSAC,\n",
    "                                     ransacReprojThreshold=5.0, # Default threshold, might need tuning\n",
    "                                     maxIters=2000,             # Default iterations\n",
    "                                     confidence=0.99)           # Default confidence\n",
    "\n",
    "    if M is None or mask is None:\n",
    "        # print(\"Warning: RANSAC failed to find a transformation.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Check number of inliers\n",
    "    num_inliers = np.sum(mask)\n",
    "    if num_inliers < min_req_matches:\n",
    "        # print(f\"Warning: Not enough RANSAC inliers ({num_inliers} < {min_req_matches})\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Decompose the Affine matrix M = [[a, b, tx], [c, d, ty]]\n",
    "    # Extract translation\n",
    "    tx = M[0, 2]\n",
    "    ty = M[1, 2]\n",
    "    trans_px_tl = (tx, ty)\n",
    "\n",
    "    # Extract rotation angle: angle_rad = atan2(sin(A), cos(A)) = A\n",
    "    angle_rad = math.atan2(M[1, 0], M[0, 0])\n",
    "    angle_deg_raw = np.degrees(angle_rad)\n",
    "\n",
    "    # Convert to anti-clockwise image rotation (0-360)\n",
    "    angle_deg = angle_deg_raw % 360\n",
    "    # Ensure positive range [0, 360)\n",
    "    # if angle_deg < 0: angle_deg += 360 # Modulo handles negativity correctly in Python? Let's be safe.\n",
    "    # Python's % operator preserves the sign of the divisor. For -10 % 360 -> 350. So it should be okay.\n",
    "\n",
    "    return M, angle_deg, trans_px_tl, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f9180d-9cbd-4e85-8cc6-cc2c06fdd7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Function for Coordinate Conversion (No Changes Needed)\n",
    "# Works on translation, angle, and shapes, independent of feature type.\n",
    "\n",
    "def convert_to_relative_center_coords(trans_px_tl, angle_deg, query_shape, ref_shape):\n",
    "    \"\"\"\n",
    "    Converts the translation relative to top-left corners and rotation\n",
    "    to the translation relative to image centers, using the user's convention.\n",
    "\n",
    "    Args:\n",
    "        trans_px_tl (tuple): (tx, ty) translation from query top-left to ref top-left (OpenCV standard).\n",
    "        angle_deg (float): Anti-clockwise rotation angle in degrees.\n",
    "        query_shape (tuple): (height, width) of the query image.\n",
    "        ref_shape (tuple): (height, width) of the reference image.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (rel_x, rel_y) relative center coordinates (+x down, +y right).\n",
    "               Returns (None, None) if input is invalid.\n",
    "    \"\"\"\n",
    "    if trans_px_tl is None or angle_deg is None:\n",
    "        return None, None\n",
    "\n",
    "    q_h, q_w = query_shape[:2]\n",
    "    r_h, r_w = ref_shape[:2]\n",
    "\n",
    "    # Reference image center (in OpenCV coords: origin top-left, +x right, +y down)\n",
    "    ref_center_cv_x = r_w / 2.0\n",
    "    ref_center_cv_y = r_h / 2.0\n",
    "\n",
    "    # Query image center (in its own local coords: origin top-left)\n",
    "    query_center_local_x = q_w / 2.0\n",
    "    query_center_local_y = q_h / 2.0\n",
    "\n",
    "    # Reconstruct the affine matrix using the estimated components (assuming scale=1 implicitly from estimateAffine2D)\n",
    "    # M already estimated by estimate_transform handles scale/shear if present\n",
    "    angle_rad = np.radians(angle_deg)\n",
    "    cos_a = np.cos(angle_rad)\n",
    "    sin_a = np.sin(angle_rad)\n",
    "    tx, ty = trans_px_tl\n",
    "\n",
    "    # We need the matrix M that maps query points to ref points.\n",
    "    # Let's assume estimate_transform returned the correct M for the transformation.\n",
    "    # If M wasn't returned, we can reconstruct an approximate one (less accurate if there was scale/shear)\n",
    "    # For now, let's assume we have M or reconstruct it simply.\n",
    "    # Reconstructing simply (may be slightly inaccurate if estimate_transform result had scale/shear):\n",
    "    M_approx = np.array([\n",
    "        [cos_a, -sin_a, tx],\n",
    "        [sin_a,  cos_a, ty]\n",
    "    ])\n",
    "\n",
    "    # Transform the query center using the affine matrix\n",
    "    query_center_in_ref_x = M_approx[0, 0] * query_center_local_x + M_approx[0, 1] * query_center_local_y + M_approx[0, 2]\n",
    "    query_center_in_ref_y = M_approx[1, 0] * query_center_local_x + M_approx[1, 1] * query_center_local_y + M_approx[1, 2]\n",
    "\n",
    "    # Find the vector from the reference center to the query center (in OpenCV coords)\n",
    "    vec_cv_x = query_center_in_ref_x - ref_center_cv_x\n",
    "    vec_cv_y = query_center_in_ref_y - ref_center_cv_y\n",
    "\n",
    "    # Convert this vector to the user's coordinate system (+x down, +y right)\n",
    "    rel_x = vec_cv_y # User's x is OpenCV's y\n",
    "    rel_y = vec_cv_x # User's y is OpenCV's x\n",
    "\n",
    "    return rel_x, rel_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26ee4664-d6fd-4118-b431-5005736adba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SuperGlue model (SIFT version, float32)...\n",
      "SuperGlue model loaded successfully (intended for float32) to device: cuda.\n",
      "SIFT detector ready.\n",
      "\n",
      "--- Cell 5 Finished ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Load SuperGlue Model (SIFT Version - MODIFIED FOR float32)\n",
    "\n",
    "# Ensure Path is available if running standalone after restart\n",
    "from pathlib import Path\n",
    "import torch # Ensure torch is available\n",
    "\n",
    "# Assume superglue_config, device, superglue_sift_repo_path are defined from Cell 1\n",
    "# Assume SuperGlue class is imported from Cell 1\n",
    "\n",
    "print(\"Loading SuperGlue model (SIFT version, float32)...\")\n",
    "\n",
    "# Instantiate the SuperGlue model from the cloned repository\n",
    "# Assumes 'SuperGlue' class was successfully imported in Cell 1\n",
    "try:\n",
    "    # Check if config exists (defined in Cell 1)\n",
    "    if 'superglue_config' not in locals():\n",
    "        raise NameError(\"superglue_config dictionary not found. Run Cell 1.\")\n",
    "    if 'device' not in locals():\n",
    "         raise NameError(\"device variable not found. Run Cell 1.\")\n",
    "\n",
    "    weights_path = superglue_config['weights_path']\n",
    "    if not Path(weights_path).is_file():\n",
    "         raise FileNotFoundError(f\"SuperGlue weights not found at {weights_path}\")\n",
    "\n",
    "    # Initialize model with config\n",
    "    # Assumes SuperGlue class was imported correctly in Cell 1\n",
    "    superglue = SuperGlue(superglue_config).eval().to(device)\n",
    "\n",
    "    # --- NO .double() CALL HERE ---\n",
    "    # This assumes you modified models/superglue.py to remove internal .double() calls\n",
    "\n",
    "    print(f\"SuperGlue model loaded successfully (intended for float32) to device: {device}.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "     print(f\"ERROR: {e}\")\n",
    "     print(\"Please ensure the weights path in superglue_config (Cell 1) is correct and the file exists.\")\n",
    "     superglue = None # Set to None to prevent errors later\n",
    "except NameError as e:\n",
    "     print(f\"ERROR: A required variable from Cell 1 is missing: {e}\")\n",
    "     superglue = None\n",
    "except AttributeError as e:\n",
    "     # This might happen if SuperGlue class wasn't imported correctly in Cell 1\n",
    "     print(f\"ERROR: Could not find SuperGlue class or method. Import failed or class name incorrect?\")\n",
    "     if 'superglue_sift_repo_path' in locals():\n",
    "          print(f\"       (Looking in: {superglue_sift_repo_path})\")\n",
    "     print(f\"       Error details: {e}\")\n",
    "     superglue = None\n",
    "except Exception as e:\n",
    "     print(f\"ERROR: Failed to load SuperGlue model. Details: {e}\")\n",
    "     # import traceback\n",
    "     # traceback.print_exc() # Uncomment for detailed traceback\n",
    "     superglue = None\n",
    "\n",
    "# SIFT detector check (assumes 'sift' was defined in Cell 1)\n",
    "if 'sift' not in locals() or sift is None:\n",
    "     print(\"ERROR: SIFT detector not available (check Cell 1).\")\n",
    "else:\n",
    "     print(\"SIFT detector ready.\")\n",
    "\n",
    "print(\"\\n--- Cell 5 Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb59e1-56fb-49b0-ada5-39e7d2b50377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting image processing loop for ALL files at 2025-04-18 23:54:18...\n",
      "Found 2040 query images. Processing...\n",
      "--- Processing file 1/2040: (10002,10091)_(-404.91,33.19)_145.08_mumbai.png ---\n",
      "!! Error processing file (10002,10091)_(-404.91,33.19)_145.08_mumbai.png (Error #1): CUDA out of memory. Tried to allocate 516.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 310.38 MiB is free. Process 15497 has 48.00 MiB memory in use. Including non-PyTorch memory, this process has 3.45 GiB memory in use. Of the allocated memory 3.04 GiB is allocated by PyTorch, and 347.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "!! Error processing file (10004,13940)_(-316.73,-56.63)_267.36_mumbai.png (Error #2): CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 248.38 MiB is free. Process 15497 has 48.00 MiB memory in use. Including non-PyTorch memory, this process has 3.51 GiB memory in use. Of the allocated memory 2.75 GiB is allocated by PyTorch, and 710.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "!! Error processing file (10011,4674)_(299.89,-40.05)_28.32_delhi.png (Error #3): CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 248.38 MiB is free. Process 15497 has 48.00 MiB memory in use. Including non-PyTorch memory, this process has 3.51 GiB memory in use. Of the allocated memory 2.81 GiB is allocated by PyTorch, and 647.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "!! Error processing file (10011,7967)_(-294.7,-279.13)_165.27_mumbai2.png (Error #4): CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 198.38 MiB is free. Process 15497 has 48.00 MiB memory in use. Including non-PyTorch memory, this process has 3.56 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 157.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "!! Error processing file (10022,11994)_(-25.57,224.63)_175.03_mumbai.png (Error #5): CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 198.38 MiB is free. Process 15497 has 48.00 MiB memory in use. Including non-PyTorch memory, this process has 3.56 GiB memory in use. Of the allocated memory 2.61 GiB is allocated by PyTorch, and 902.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "!! Error processing file (10022,4888)_(-390.33,-101.79)_142.63_delhi.png (Error #6): CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 102.38 MiB is free. Process 15497 has 48.00 MiB memory in use. Including non-PyTorch memory, this process has 3.65 GiB memory in use. Of the allocated memory 3.04 GiB is allocated by PyTorch, and 560.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "!! Error processing file (10029,3371)_(-219.62,-106.29)_310.24_mumbai.png (Error #7): CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 102.38 MiB is free. Process 15497 has 48.00 MiB memory in use. Including non-PyTorch memory, this process has 3.65 GiB memory in use. Of the allocated memory 3.04 GiB is allocated by PyTorch, and 560.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "!! Error processing file (10036,4811)_(161.53,283.38)_207.75_mumbai.png (Error #8): CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 102.38 MiB is free. Process 15497 has 48.00 MiB memory in use. Including non-PyTorch memory, this process has 3.65 GiB memory in use. Of the allocated memory 3.04 GiB is allocated by PyTorch, and 560.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "!! Error processing file (10048,1195)_(444.63,149.68)_24.23_mumbai.png (Error #9): CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 102.38 MiB is free. Process 15497 has 48.00 MiB memory in use. Including non-PyTorch memory, this process has 3.65 GiB memory in use. Of the allocated memory 3.04 GiB is allocated by PyTorch, and 560.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "--- Processing file 50/2040: (10241,1478)_(-281.02,195.0)_109.50_mumbai.png ---\n",
      "!! Error processing file (10241,1478)_(-281.02,195.0)_109.50_mumbai.png (Error #50): CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 86.38 MiB is free. Process 15497 has 48.00 MiB memory in use. Including non-PyTorch memory, this process has 3.67 GiB memory in use. Of the allocated memory 3.28 GiB is allocated by PyTorch, and 325.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "--- Processing file 100/2040: (1045,13366)_(-144.33,-81.03)_197.16_mumbai.png ---\n",
      "!! Error processing file (1045,13366)_(-144.33,-81.03)_197.16_mumbai.png (Error #100): CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 76.38 MiB is free. Process 15497 has 48.00 MiB memory in use. Including non-PyTorch memory, this process has 3.68 GiB memory in use. Of the allocated memory 2.93 GiB is allocated by PyTorch, and 700.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "--- Processing file 150/2040: (10620,10609)_(80.54,142.94)_20.28_mumbai2.png ---\n",
      "!! Error processing file (10620,10609)_(80.54,142.94)_20.28_mumbai2.png (Error #150): CUDA out of memory. Tried to allocate 470.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 74.38 MiB is free. Process 15497 has 48.00 MiB memory in use. Including non-PyTorch memory, this process has 3.68 GiB memory in use. Of the allocated memory 2.88 GiB is allocated by PyTorch, and 750.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Main Processing Loop (SIFT Version - PROCESS ALL IMAGES)\n",
    "\n",
    "import traceback # Import for detailed error printing\n",
    "import time # Ensure time is available if not imported globally\n",
    "# Ensure Path is imported if running this cell standalone after restart\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize lists and counters\n",
    "results = []\n",
    "all_filenames = []\n",
    "processing_errors = 0\n",
    "\n",
    "# Check if model and detector loaded successfully before starting\n",
    "if 'superglue' not in locals() or 'sift' not in locals() or superglue is None or sift is None:\n",
    "    print(\"\\nERROR: SuperGlue model or SIFT detector not available (check Cell 1 and Cell 5).\")\n",
    "    print(\"Cannot proceed with processing loop.\")\n",
    "else:\n",
    "    print(f\"\\nStarting image processing loop for ALL files at {time.strftime('%Y-%m-%d %H:%M:%S')}...\")\n",
    "    # Ensure directories exist\n",
    "    if not QUERY_DIR.is_dir() or not REF_DIR.is_dir():\n",
    "        print(f\"ERROR: Query directory '{QUERY_DIR.resolve()}' or Reference directory '{REF_DIR.resolve()}' not found.\")\n",
    "    else:\n",
    "        # Get list of query images, ignoring hidden files\n",
    "        query_files = sorted([f for f in QUERY_DIR.iterdir() if f.is_file() and not f.name.startswith('.') and f.suffix.lower() == '.png'])\n",
    "\n",
    "        if not query_files:\n",
    "            print(f\"No PNG files found in {QUERY_DIR}\")\n",
    "        else:\n",
    "            total_files = len(query_files)\n",
    "            print(f\"Found {total_files} query images. Processing...\")\n",
    "\n",
    "            for i, query_path in enumerate(query_files):\n",
    "                filename = query_path.name\n",
    "                ref_path = REF_DIR / filename\n",
    "\n",
    "                # Print progress periodically\n",
    "                if (i + 1) % 50 == 0 or i == 0:\n",
    "                    print(f\"--- Processing file {i+1}/{total_files}: {filename} ---\")\n",
    "\n",
    "                if not ref_path.exists():\n",
    "                    # print(f\"  Warning: Reference image not found for {filename}. Skipping.\") # Optional: uncomment for verbose skipping\n",
    "                    # Add failure record for missing reference\n",
    "                    results.append({'filename': filename, 'query_path': str(query_path), 'ref_path': str(ref_path), 'error': 'Reference Missing'})\n",
    "                    all_filenames.append(filename)\n",
    "                    processing_errors += 1\n",
    "                    continue # Skip to the next file\n",
    "\n",
    "                # 1. Parse Ground Truth\n",
    "                ground_truth = parse_filename(query_path) # Use query path for parsing convention\n",
    "                if ground_truth is None:\n",
    "                    # print(f\"  Warning: Failed to parse ground truth for {filename}. Skipping processing.\") # Optional: uncomment\n",
    "                    results.append({'filename': filename, 'query_path': str(query_path), 'ref_path': str(ref_path), 'error': 'Filename Parsing Error'})\n",
    "                    all_filenames.append(filename)\n",
    "                    processing_errors += 1\n",
    "                    continue # Skip file if parsing failed\n",
    "\n",
    "                # --- Start Try Block for Core Processing ---\n",
    "                try:\n",
    "                    # 2. Load Images (as grayscale for SIFT)\n",
    "                    img0_bgr = cv2.imread(str(query_path), cv2.IMREAD_COLOR)\n",
    "                    img1_bgr = cv2.imread(str(ref_path), cv2.IMREAD_COLOR)\n",
    "                    if img0_bgr is None or img1_bgr is None: raise ValueError(\"Image loading failed\")\n",
    "                    img0_gray = cv2.cvtColor(img0_bgr, cv2.COLOR_BGR2GRAY)\n",
    "                    img1_gray = cv2.cvtColor(img1_bgr, cv2.COLOR_BGR2GRAY)\n",
    "                    query_h, query_w = img0_gray.shape[:2]\n",
    "                    ref_h, ref_w = img1_gray.shape[:2]\n",
    "\n",
    "                    # 3. Detect SIFT features and compute descriptors\n",
    "                    # Using sift object defined in Cell 1 (potentially with nfeatures limit)\n",
    "                    kp0_sift, desc0_sift = sift.detectAndCompute(img0_gray, None)\n",
    "                    kp1_sift, desc1_sift = sift.detectAndCompute(img1_gray, None)\n",
    "                    num_kp0 = len(kp0_sift) if kp0_sift is not None else 0\n",
    "                    num_kp1 = len(kp1_sift) if kp1_sift is not None else 0\n",
    "                    if desc0_sift is None or desc1_sift is None or num_kp0 == 0 or num_kp1 == 0: raise ValueError(f\"SIFT Failure (KP0={num_kp0}, KP1={num_kp1})\")\n",
    "\n",
    "                    # 4. Prepare data for SuperGlue (with workarounds)\n",
    "                    kpts0 = np.array([kp.pt for kp in kp0_sift], dtype=np.float32)\n",
    "                    kpts1 = np.array([kp.pt for kp in kp1_sift], dtype=np.float32)\n",
    "                    scores0 = np.array([kp.response for kp in kp0_sift], dtype=np.float32)\n",
    "                    scores1 = np.array([kp.response for kp in kp1_sift], dtype=np.float32)\n",
    "                    desc0 = desc0_sift.T; desc1 = desc1_sift.T\n",
    "                    kpts0_tensor = torch.from_numpy(kpts0).unsqueeze(0).to(device)\n",
    "                    kpts1_tensor = torch.from_numpy(kpts1).unsqueeze(0).to(device)\n",
    "                    desc0_tensor = torch.from_numpy(desc0).unsqueeze(0).to(device)\n",
    "                    desc1_tensor = torch.from_numpy(desc1).unsqueeze(0).to(device)\n",
    "                    scores0_tensor = torch.from_numpy(scores0).unsqueeze(1).to(device) # Shape: (N, 1) - Workaround!\n",
    "                    scores1_tensor = torch.from_numpy(scores1).unsqueeze(1).to(device) # Shape: (N, 1) - Workaround!\n",
    "                    img0_size = torch.tensor([[query_h, query_w]], dtype=torch.float32, device=device)\n",
    "                    img1_size = torch.tensor([[ref_h, ref_w]], dtype=torch.float32, device=device)\n",
    "                    image0_tensor = torch.from_numpy(img0_gray).float()[None, None].to(device) / 255.0\n",
    "                    image1_tensor = torch.from_numpy(img1_gray).float()[None, None].to(device) / 255.0\n",
    "\n",
    "                    pred_input = {\n",
    "                        'keypoints0': kpts0_tensor, 'scores0': scores0_tensor, 'descriptors0': desc0_tensor, 'image_size0': img0_size, 'image0': image0_tensor,\n",
    "                        'keypoints1': kpts1_tensor, 'scores1': scores1_tensor, 'descriptors1': desc1_tensor, 'image_size1': img1_size, 'image1': image1_tensor,\n",
    "                        'file_name': filename,\n",
    "                        'all_matches': torch.empty((1, 0, 2), dtype=torch.long).to(device), # Placeholder\n",
    "                    }\n",
    "\n",
    "                    # 5. Perform SuperGlue Matching\n",
    "                    with torch.no_grad():\n",
    "                        pred = superglue(pred_input) # Model call\n",
    "\n",
    "                    # 6. Extract Matches and Confidences\n",
    "                    matches0 = pred.get('matches0', [None])[0]; match_conf = pred.get('matching_scores0', [None])[0]\n",
    "                    if matches0 is None or match_conf is None: raise ValueError(\"SuperGlue Output Format Error\")\n",
    "                    matches0 = matches0.cpu().numpy(); match_conf = match_conf.cpu().numpy()\n",
    "\n",
    "                    # Filter matches\n",
    "                    valid_match_mask = (matches0 > -1) & (match_conf > superglue_config['match_threshold'])\n",
    "                    match_indices0 = np.where(valid_match_mask)[0]\n",
    "                    num_good_matches = len(match_indices0)\n",
    "\n",
    "                    # Get coordinates\n",
    "                    mkpts0 = kpts0[match_indices0]\n",
    "                    # Important fix: Ensure indices used for kpts1 are valid\n",
    "                    valid_matches1 = matches0[valid_match_mask]\n",
    "                    if np.any(valid_matches1 >= len(kpts1)): # Check if any index is out of bounds for kpts1\n",
    "                        raise IndexError(f\"Invalid match index found for kpts1 (max index: {len(kpts1)-1}, found: {valid_matches1.max()})\")\n",
    "                    mkpts1 = kpts1[valid_matches1]\n",
    "\n",
    "\n",
    "                    # 7. Estimate Transformation\n",
    "                    M, pred_angle, trans_px_tl, mask = estimate_transform(mkpts0, mkpts1) # Uses Cell 3 function\n",
    "\n",
    "                    # 8. Convert Coordinates\n",
    "                    if M is not None:\n",
    "                        pred_x, pred_y = convert_to_relative_center_coords(trans_px_tl, pred_angle, (query_h, query_w), (ref_h, ref_w))\n",
    "                    else:\n",
    "                        pred_x, pred_y, pred_angle = None, None, None # Prediction failed\n",
    "\n",
    "                    # 9. Store Results\n",
    "                    results.append({\n",
    "                        'filename': filename, 'query_path': str(query_path), 'ref_path': str(ref_path),\n",
    "                        'gt_x': ground_truth.get('x'), 'gt_y': ground_truth.get('y'), 'gt_angle': ground_truth.get('angle'),\n",
    "                        'pred_x': pred_x, 'pred_y': pred_y, 'pred_angle': pred_angle,\n",
    "                        'query_shape': (query_h, query_w), 'ref_shape': (ref_h, ref_w),\n",
    "                        'error': None # No error in this try block path\n",
    "                    })\n",
    "                    all_filenames.append(filename)\n",
    "\n",
    "                # --- End Try Block ---\n",
    "                except Exception as e:\n",
    "                    processing_errors += 1\n",
    "                    # Reduce print frequency for errors during full run unless debugging needed\n",
    "                    if processing_errors < 10 or (i+1)%50==0: # Print first few errors and periodically\n",
    "                         print(f\"!! Error processing file {filename} (Error #{processing_errors}): {e}\")\n",
    "                         # print(\"\\n--- TRACEBACK ---\"); traceback.print_exc(); print(\"--- END TRACEBACK ---\\n\") # Keep commented unless debugging\n",
    "                    # Store failure information\n",
    "                    results.append({\n",
    "                        'filename': filename, 'query_path': str(query_path), 'ref_path': str(ref_path),\n",
    "                        'gt_x': ground_truth.get('x'), 'gt_y': ground_truth.get('y'), 'gt_angle': ground_truth.get('angle'),\n",
    "                        'pred_x': None, 'pred_y': None, 'pred_angle': None,\n",
    "                        'error': str(e)\n",
    "                    })\n",
    "                    all_filenames.append(filename)\n",
    "\n",
    "            # --- End For Loop ---\n",
    "            print(f\"\\nProcessing finished at {time.strftime('%Y-%m-%d %H:%M:%S')}.\")\n",
    "            successful_run_count = len(results) - processing_errors # Approximation, as errors might happen before appending\n",
    "            print(f\"Attempted {len(all_filenames)} files.\") # Use all_filenames length for total attempts\n",
    "            print(f\"Entries added to results list: {len(results)}\")\n",
    "            print(f\"Encountered {processing_errors} errors during processing loop.\")\n",
    "\n",
    "# --- End of Cell 6 ---\n",
    "print(\"\\n--- Cell 6 Finished (Full Dataset Mode) ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c5356-fc63-45f5-a81d-77938b9e1919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Calculate Accuracy Metrics (No Changes Needed)\n",
    "# Same code as before, calculates metrics based on the 'results' list.\n",
    "\n",
    "coord_errors = []\n",
    "angle_errors = []\n",
    "successful_predictions = 0\n",
    "\n",
    "print(\"\\nCalculating accuracy metrics...\")\n",
    "if not results:\n",
    "     print(\"No results to analyze.\")\n",
    "else:\n",
    "    for res in results:\n",
    "        # Check if prediction fields exist and are not None\n",
    "        if res.get('pred_x') is not None and res.get('pred_y') is not None and res.get('pred_angle') is not None:\n",
    "            successful_predictions += 1\n",
    "\n",
    "            # Coordinate Error (Euclidean Distance)\n",
    "            dx = res['pred_x'] - res['gt_x']\n",
    "            dy = res['pred_y'] - res['gt_y']\n",
    "            coord_err = np.sqrt(dx**2 + dy**2)\n",
    "            coord_errors.append(coord_err)\n",
    "\n",
    "            # Angle Error (handle wrap-around)\n",
    "            angle_diff = abs(res['pred_angle'] - res['gt_angle'])\n",
    "            angle_err = min(angle_diff, 360.0 - angle_diff)\n",
    "            angle_errors.append(angle_err)\n",
    "        # else: prediction failed or errored, skip metrics for this entry\n",
    "\n",
    "    print(f\"\\n--- Accuracy Metrics ({successful_predictions} successful predictions out of {len(results)} total entries) ---\")\n",
    "    if successful_predictions > 0:\n",
    "        mean_coord_error = np.mean(coord_errors)\n",
    "        median_coord_error = np.median(coord_errors)\n",
    "        std_coord_error = np.std(coord_errors)\n",
    "\n",
    "        mean_angle_error = np.mean(angle_errors)\n",
    "        median_angle_error = np.median(angle_errors)\n",
    "        std_angle_error = np.std(angle_errors)\n",
    "\n",
    "        print(f\"Coordinate Error (pixels):\")\n",
    "        print(f\"  Mean:   {mean_coord_error:.3f}\")\n",
    "        print(f\"  Median: {median_coord_error:.3f}\")\n",
    "        print(f\"  StdDev: {std_coord_error:.3f}\")\n",
    "\n",
    "        print(f\"\\nAngle Error (degrees):\")\n",
    "        print(f\"  Mean:   {mean_angle_error:.3f}\")\n",
    "        print(f\"  Median: {median_angle_error:.3f}\")\n",
    "        print(f\"  StdDev: {std_angle_error:.3f}\")\n",
    "\n",
    "        # Optional: Histograms\n",
    "        # plt.figure(figsize=(12, 5))\n",
    "        # plt.subplot(1, 2, 1); plt.hist(coord_errors, bins=50); plt.title('Coordinate Error Distribution'); plt.xlabel('Error (pixels)'); plt.ylabel('Frequency')\n",
    "        # plt.subplot(1, 2, 2); plt.hist(angle_errors, bins=50); plt.title('Angle Error Distribution'); plt.xlabel('Error (degrees)'); plt.ylabel('Frequency')\n",
    "        # plt.tight_layout(); plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"No successful predictions were made to calculate metrics.\")\n",
    "\n",
    "    total_processed = len(results) # Number of entries in results list\n",
    "    failure_rate = ((total_processed - successful_predictions) / total_processed * 100) if total_processed > 0 else 0\n",
    "    print(f\"\\nTotal entries processed: {total_processed}\")\n",
    "    print(f\"Prediction success rate: {100 - failure_rate:.2f}%\")\n",
    "    print(f\"Prediction failure/error rate: {failure_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57340109-90dd-4091-a33a-3a7d35c22b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Visualization Function (No Changes Needed)\n",
    "# Same function as before, uses image paths and predicted/GT coordinates.\n",
    "\n",
    "def get_rotated_rect_corners(center_x, center_y, w, h, angle_deg, ref_shape):\n",
    "    \"\"\"\n",
    "    Calculates the four corner points of a rectangle rotated around its center.\n",
    "    Center coordinates are relative to the reference image center (+x down, +y right).\n",
    "    Angle is anti-clockwise degrees.\n",
    "    Returns corners in OpenCV format (integer tuples, origin top-left).\n",
    "    \"\"\"\n",
    "    if None in [center_x, center_y, w, h, angle_deg, ref_shape] or None in ref_shape:\n",
    "        print(\"Warning: Invalid input to get_rotated_rect_corners.\")\n",
    "        return None # Return None if any input is invalid\n",
    "\n",
    "    r_h, r_w = ref_shape[:2]\n",
    "    ref_center_cv_x = r_w / 2.0\n",
    "    ref_center_cv_y = r_h / 2.0\n",
    "\n",
    "    # Convert user center coords back to OpenCV top-left origin coords\n",
    "    center_cv_x = center_y + ref_center_cv_x # User y is CV x\n",
    "    center_cv_y = center_x + ref_center_cv_y # User x is CV y\n",
    "\n",
    "    # Angle for rotation matrix (negative for rotating points)\n",
    "    angle_rad = np.radians(-angle_deg)\n",
    "    cos_a = np.cos(angle_rad)\n",
    "    sin_a = np.sin(angle_rad)\n",
    "\n",
    "    # Rectangle corners relative to its center (0,0)\n",
    "    hw = w / 2.0\n",
    "    hh = h / 2.0\n",
    "    corners_local = np.array([\n",
    "        [-hw, -hh], [ hw, -hh], [ hw,  hh], [-hw,  hh]\n",
    "    ])\n",
    "\n",
    "    # Rotate and translate corners\n",
    "    corners_rotated = np.zeros_like(corners_local)\n",
    "    for i, (x, y) in enumerate(corners_local):\n",
    "        x_rot = x * cos_a - y * sin_a\n",
    "        y_rot = x * sin_a + y * cos_a\n",
    "        corners_rotated[i, 0] = x_rot + center_cv_x\n",
    "        corners_rotated[i, 1] = y_rot + center_cv_y\n",
    "\n",
    "    return corners_rotated.astype(int)\n",
    "\n",
    "\n",
    "def visualize_result(result_data, border_thickness=3):\n",
    "    \"\"\"\n",
    "    Visualizes the query, reference, and localization boxes (predicted vs ground truth).\n",
    "    Handles cases where prediction failed (pred_x is None).\n",
    "    \"\"\"\n",
    "    query_img_bgr = cv2.imread(result_data.get('query_path', ''))\n",
    "    ref_img_bgr = cv2.imread(result_data.get('ref_path', ''))\n",
    "\n",
    "    if query_img_bgr is None or ref_img_bgr is None:\n",
    "        print(f\"Error loading images for visualization: {result_data.get('filename', 'N/A')}\")\n",
    "        # Create placeholder images maybe? Or just don't plot.\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        plt.text(0.5, 0.5, f\"Error loading images for\\n{result_data.get('filename', 'N/A')}\",\n",
    "                 horizontalalignment='center', verticalalignment='center')\n",
    "        plt.title(\"Visualization Error\")\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    q_h, q_w = result_data.get('query_shape', (None, None))[:2]\n",
    "    ref_shape = result_data.get('ref_shape', (None, None))\n",
    "\n",
    "    if q_h is None or q_w is None or ref_shape[0] is None or ref_shape[1] is None:\n",
    "        print(f\"Error: Missing shape information for {result_data.get('filename', 'N/A')}\")\n",
    "        # Plot images without boxes?\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "        axes[0].imshow(cv2.cvtColor(query_img_bgr, cv2.COLOR_BGR2RGB)); axes[0].set_title(\"Query\"); axes[0].axis('off')\n",
    "        axes[1].imshow(cv2.cvtColor(ref_img_bgr, cv2.COLOR_BGR2RGB)); axes[1].set_title(\"Reference (Shape Error)\"); axes[1].axis('off')\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "\n",
    "    # --- Draw Ground Truth Box (Green) ---\n",
    "    # Ensure GT values are present before drawing\n",
    "    gt_present = all(k in result_data and result_data[k] is not None for k in ['gt_x', 'gt_y', 'gt_angle'])\n",
    "    if gt_present:\n",
    "         gt_corners = get_rotated_rect_corners(\n",
    "             result_data['gt_x'], result_data['gt_y'],\n",
    "             q_w, q_h, result_data['gt_angle'], ref_shape\n",
    "         )\n",
    "         if gt_corners is not None:\n",
    "              cv2.polylines(ref_img_bgr, [gt_corners], isClosed=True, color=(0, 255, 0), thickness=border_thickness) # Green\n",
    "    else:\n",
    "        print(f\"Warning: Ground truth data missing for {result_data.get('filename', 'N/A')}. Skipping GT box.\")\n",
    "\n",
    "\n",
    "    # --- Draw Predicted Box (Red) ---\n",
    "    pred_status = \"Failed\"\n",
    "    error_text = result_data.get('error', \"Prediction Failed\") # Use stored error if available\n",
    "    pred_present = all(k in result_data and result_data[k] is not None for k in ['pred_x', 'pred_y', 'pred_angle'])\n",
    "\n",
    "    if pred_present:\n",
    "        pred_corners = get_rotated_rect_corners(\n",
    "            result_data['pred_x'], result_data['pred_y'],\n",
    "            q_w, q_h, result_data['pred_angle'], ref_shape\n",
    "        )\n",
    "        if pred_corners is not None:\n",
    "             cv2.polylines(ref_img_bgr, [pred_corners], isClosed=True, color=(0, 0, 255), thickness=border_thickness) # Red\n",
    "             pred_status = \"Successful\"\n",
    "             # Calculate errors on the fly if not stored, requires GT to be present\n",
    "             if gt_present:\n",
    "                  dx = result_data['pred_x'] - result_data['gt_x']\n",
    "                  dy = result_data['pred_y'] - result_data['gt_y']\n",
    "                  coord_err = np.sqrt(dx**2 + dy**2)\n",
    "                  angle_diff = abs(result_data['pred_angle'] - result_data['gt_angle'])\n",
    "                  angle_err = min(angle_diff, 360.0 - angle_diff)\n",
    "                  error_text = f\"Coord Err: {coord_err:.2f}px, Angle Err: {angle_err:.2f}deg\"\n",
    "             else:\n",
    "                  error_text = \"Pred OK, GT Missing\"\n",
    "    # else: pred_status remains \"Failed\", error_text uses default or stored error\n",
    "\n",
    "    # --- Display using Matplotlib ---\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "    # Display Query Image\n",
    "    axes[0].imshow(cv2.cvtColor(query_img_bgr, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title(f\"Query: {result_data.get('filename', 'N/A')}\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Display Reference Image with Boxes\n",
    "    axes[1].imshow(cv2.cvtColor(ref_img_bgr, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title(f\"Reference (GT=Green, Pred=Red) - Status: {pred_status}\")\n",
    "    # Display error text calculated above or stored error message\n",
    "    axes[1].text(5, 25, error_text, color='yellow', fontsize=9, bbox=dict(facecolor='black', alpha=0.6))\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Format GT and Pred strings safely using .get with default values\n",
    "    gt_x_str = f\"{result_data.get('gt_x', 'N/A'):.2f}\" if result_data.get('gt_x') is not None else 'N/A'\n",
    "    gt_y_str = f\"{result_data.get('gt_y', 'N/A'):.2f}\" if result_data.get('gt_y') is not None else 'N/A'\n",
    "    gt_a_str = f\"{result_data.get('gt_angle', 'N/A'):.2f}\" if result_data.get('gt_angle') is not None else 'N/A'\n",
    "    gt_info = f\"GT: ({gt_x_str}, {gt_y_str}), {gt_a_str}°\"\n",
    "\n",
    "    pred_x_str = f\"{result_data.get('pred_x', 'N/A'):.2f}\" if result_data.get('pred_x') is not None else 'N/A'\n",
    "    pred_y_str = f\"{result_data.get('pred_y', 'N/A'):.2f}\" if result_data.get('pred_y') is not None else 'N/A'\n",
    "    pred_a_str = f\"{result_data.get('pred_angle', 'N/A'):.2f}\" if result_data.get('pred_angle') is not None else 'N/A'\n",
    "    pred_info = f\"Pred: ({pred_x_str}, {pred_y_str}), {pred_a_str}°\" if pred_status == \"Successful\" else f\"Pred: {pred_status}\"\n",
    "\n",
    "    plt.suptitle(f\"{gt_info}\\n{pred_info}\", y=0.95)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.9])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1885a04-ee2a-4c4b-82cc-70dae8eef89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8.5: Separate Results and Calculate Errors (SIFT Version)\n",
    "# No changes needed from the version used previously, as it just processes the 'results' list.\n",
    "# Ensure error calculation handles potential None values robustly.\n",
    "\n",
    "successful_results = []\n",
    "failed_results = []\n",
    "high_error_results = [] # New list\n",
    "\n",
    "# Define error thresholds (tune if needed)\n",
    "COORD_ERROR_THRESHOLD = 50.0 # pixels\n",
    "ANGLE_ERROR_THRESHOLD = 20.0 # degrees\n",
    "\n",
    "print(\"\\nSeparating results and calculating errors...\")\n",
    "# Check if 'results' variable exists and is a list\n",
    "if 'results' not in locals() or not isinstance(results, list):\n",
    "    print(\"=\"*60)\n",
    "    print(\"ERROR: 'results' variable not found or is not a list.\")\n",
    "    print(\"Please ensure Cell 6 (Main Processing Loop) has been run.\")\n",
    "    print(\"=\"*60)\n",
    "    # Define empty lists to prevent errors later\n",
    "    successful_results = []\n",
    "    failed_results = []\n",
    "    high_error_results = []\n",
    "else:\n",
    "    # Iterate through the existing results list\n",
    "    for res in results:\n",
    "        # Check if prediction was successful (all prediction fields present and not None)\n",
    "        is_successful = (res.get('pred_x') is not None and\n",
    "                         res.get('pred_y') is not None and\n",
    "                         res.get('pred_angle') is not None)\n",
    "\n",
    "        if is_successful:\n",
    "            # Ensure ground truth is also present for error calculation\n",
    "            gt_present = (res.get('gt_x') is not None and\n",
    "                          res.get('gt_y') is not None and\n",
    "                          res.get('gt_angle') is not None)\n",
    "\n",
    "            if gt_present:\n",
    "                # Calculate errors\n",
    "                dx = res['pred_x'] - res['gt_x']\n",
    "                dy = res['pred_y'] - res['gt_y']\n",
    "                coord_err = np.sqrt(dx**2 + dy**2)\n",
    "\n",
    "                angle_diff = abs(res['pred_angle'] - res['gt_angle'])\n",
    "                angle_err = min(angle_diff, 360.0 - angle_diff)\n",
    "\n",
    "                # Store errors back into the dictionary\n",
    "                res['coord_error'] = coord_err\n",
    "                res['angle_error'] = angle_err\n",
    "\n",
    "                # Check if it qualifies for high error list\n",
    "                if coord_err > COORD_ERROR_THRESHOLD or angle_err > ANGLE_ERROR_THRESHOLD:\n",
    "                    high_error_results.append(res)\n",
    "            else:\n",
    "                 # GT missing, cannot calculate error, assign None\n",
    "                 res['coord_error'] = None\n",
    "                 res['angle_error'] = None\n",
    "\n",
    "            successful_results.append(res) # Add to successful list regardless of error calc\n",
    "\n",
    "        else:\n",
    "            # Failed prediction or processing error\n",
    "            res['coord_error'] = None # No error to calculate\n",
    "            res['angle_error'] = None\n",
    "            failed_results.append(res)\n",
    "\n",
    "    print(f\"Separation and Error Calculation complete:\")\n",
    "    print(f\"  Found {len(successful_results)} successful predictions.\")\n",
    "    print(f\"  Found {len(failed_results)} failed predictions/errors.\")\n",
    "    print(f\"  Identified {len(high_error_results)} successful predictions with high error (where calculable).\")\n",
    "\n",
    "    # Optional: Sort high_error_results if desired (e.g., by coordinate error descending)\n",
    "    # Need to handle None values if sorting\n",
    "    # high_error_results.sort(key=lambda x: x.get('coord_error', float('inf')), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10028fae-f339-42c5-b646-f9e5098188d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Visualization Loops (SIFT Version)\n",
    "# No changes needed from the version used previously, displays Failed, High-Error, and Low/Medium-Error.\n",
    "\n",
    "MAX_VIZ_EACH = 5 # Number of examples to show for each category\n",
    "\n",
    "# Check if prerequisite lists exist\n",
    "if 'failed_results' not in locals() or 'high_error_results' not in locals() or 'successful_results' not in locals():\n",
    "     print(\"ERROR: Results lists (failed, high_error, successful) not found. Please run Cell 8.5 first.\")\n",
    "else:\n",
    "    # --- Visualize FAILED Predictions ---\n",
    "    print(f\"\\n{'='*20} Visualizing up to {MAX_VIZ_EACH} FAILED Prediction Examples {'='*20}\")\n",
    "    if not failed_results:\n",
    "        print(\"\\nNo failed prediction results found to visualize.\")\n",
    "    else:\n",
    "        print(f\"\\nDisplaying the first {min(len(failed_results), MAX_VIZ_EACH)} failed examples...\")\n",
    "        count_failed = 0\n",
    "        for res in failed_results:\n",
    "            if count_failed < MAX_VIZ_EACH:\n",
    "                print(f\"\\n[{count_failed+1}/{min(len(failed_results), MAX_VIZ_EACH)}] Visualizing FAILED result for: {res.get('filename', 'N/A')}\")\n",
    "                try:\n",
    "                    visualize_result(res)\n",
    "                    count_failed += 1\n",
    "                except Exception as e:\n",
    "                     print(f\"  ERROR during visualization for {res.get('filename', 'N/A')}: {e}\")\n",
    "            else:\n",
    "                break # Stop after showing MAX_VIZ_EACH\n",
    "        if count_failed == 0 and failed_results:\n",
    "             print(\"\\nCould not visualize any of the available failed results due to errors during visualization.\")\n",
    "        print(f\"\\nFinished displaying {count_failed} failed examples.\")\n",
    "\n",
    "\n",
    "    # --- Visualize HIGH ERROR Successful Predictions ---\n",
    "    print(f\"\\n{'='*20} Visualizing up to {MAX_VIZ_EACH} HIGH ERROR Successful Prediction Examples {'='*20}\")\n",
    "    # Retrieve thresholds used in Cell 8.5 if they were defined there, otherwise redefine or display fixed values\n",
    "    coord_thresh_disp = locals().get('COORD_ERROR_THRESHOLD', 50.0) # Get from locals or use default\n",
    "    angle_thresh_disp = locals().get('ANGLE_ERROR_THRESHOLD', 20.0)\n",
    "    print(f\"(Thresholds used: Coord > {coord_thresh_disp}px OR Angle > {angle_thresh_disp}deg)\")\n",
    "\n",
    "    if not high_error_results:\n",
    "        print(\"\\nNo successful predictions with high error found to visualize.\")\n",
    "    else:\n",
    "        print(f\"\\nDisplaying the first {min(len(high_error_results), MAX_VIZ_EACH)} high-error successful examples...\")\n",
    "        count_hierr = 0\n",
    "        for res in high_error_results:\n",
    "            if count_hierr < MAX_VIZ_EACH:\n",
    "                coord_err_str = f\"{res.get('coord_error', 'N/A'):.2f}\" if res.get('coord_error') is not None else \"N/A\"\n",
    "                angle_err_str = f\"{res.get('angle_error', 'N/A'):.2f}\" if res.get('angle_error') is not None else \"N/A\"\n",
    "                print(f\"\\n[{count_hierr+1}/{min(len(high_error_results), MAX_VIZ_EACH)}] Visualizing HIGH ERROR result for: {res.get('filename', 'N/A')}\")\n",
    "                print(f\"  Errors - Coord: {coord_err_str}px, Angle: {angle_err_str}deg\")\n",
    "                try:\n",
    "                    visualize_result(res)\n",
    "                    count_hierr += 1\n",
    "                except Exception as e:\n",
    "                     print(f\"  ERROR during visualization for {res.get('filename', 'N/A')}: {e}\")\n",
    "            else:\n",
    "                break\n",
    "        if count_hierr == 0 and high_error_results:\n",
    "             print(\"\\nCould not visualize any of the available high-error results due to errors during visualization.\")\n",
    "        print(f\"\\nFinished displaying {count_hierr} high-error successful examples.\")\n",
    "\n",
    "    # --- Visualize GENERALLY Successful Predictions (filter out high errors) ---\n",
    "    print(f\"\\n{'='*20} Visualizing up to {MAX_VIZ_EACH} LOW/MEDIUM Error Successful Prediction Examples {'='*20}\")\n",
    "    if not successful_results:\n",
    "         print(\"\\nNo successful predictions found at all.\")\n",
    "    else:\n",
    "        # Filter out high-error examples already shown - use filename for robust check\n",
    "        high_error_filenames = {res.get('filename') for res in high_error_results if res.get('filename')}\n",
    "        low_med_error_results = [res for res in successful_results if res.get('filename') not in high_error_filenames]\n",
    "\n",
    "        if not low_med_error_results:\n",
    "             print(\"\\nNo successful predictions with low/medium error found (all successful had high error or failed visualization).\")\n",
    "        else:\n",
    "            print(f\"\\nDisplaying the first {min(len(low_med_error_results), MAX_VIZ_EACH)} low/medium-error successful examples...\")\n",
    "            count_success = 0\n",
    "            for res in low_med_error_results:\n",
    "                if count_success < MAX_VIZ_EACH:\n",
    "                    coord_err_str = f\"{res.get('coord_error', 'N/A'):.2f}\" if res.get('coord_error') is not None else \"N/A\"\n",
    "                    angle_err_str = f\"{res.get('angle_error', 'N/A'):.2f}\" if res.get('angle_error') is not None else \"N/A\"\n",
    "                    print(f\"\\n[{count_success+1}/{min(len(low_med_error_results), MAX_VIZ_EACH)}] Visualizing LOW/MED ERROR result for: {res.get('filename', 'N/A')}\")\n",
    "                    print(f\"  Errors - Coord: {coord_err_str}px, Angle: {angle_err_str}deg\")\n",
    "                    try:\n",
    "                        visualize_result(res)\n",
    "                        count_success += 1\n",
    "                    except Exception as e:\n",
    "                         print(f\"  ERROR during visualization for {res.get('filename', 'N/A')}: {e}\")\n",
    "                else:\n",
    "                    break\n",
    "            if count_success == 0 and low_med_error_results:\n",
    "                 print(\"\\nCould not visualize any of the available low/medium-error results due to errors during visualization.\")\n",
    "            print(f\"\\nFinished displaying {count_success} low/medium-error successful examples.\")\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Visualization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f39c77-9960-4803-b42b-977226efc227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Timing Prediction for Random Sample (SIFT Version)\n",
    "# Uses SIFT feature extraction and the new SuperGlue model.\n",
    "\n",
    "# Imports might be needed again if kernel restarted, but should be loaded\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import math\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_SAMPLES_FOR_TIMING = 5\n",
    "# Ensure these match paths used in Cell 1 and Cell 6\n",
    "QUERY_DIR = Path('./extended_dataset/camera image')\n",
    "REF_DIR = Path('./extended_dataset/reference image')\n",
    "\n",
    "print(f\"\\n--- Timing Prediction (SIFT Version) for {NUM_SAMPLES_FOR_TIMING} Random Image Pairs ---\")\n",
    "\n",
    "# --- Pre-requisite Checks ---\n",
    "# Check essential variables/functions defined in previous cells are available\n",
    "required_vars_timing = ['sift', 'superglue', 'superglue_config', 'device', 'QUERY_DIR', 'REF_DIR']\n",
    "required_funcs_timing = ['convert_to_relative_center_coords'] # Only this one is needed besides cv2/torch/np\n",
    "missing_items_timing = []\n",
    "for item_name in required_vars_timing + required_funcs_timing:\n",
    "    if item_name not in locals():\n",
    "         missing_items_timing.append(item_name)\n",
    "\n",
    "if missing_items_timing:\n",
    "    print(\"\\nERROR: Missing required variables or functions for timing.\")\n",
    "    print(f\"  Missing: {', '.join(missing_items_timing)}\")\n",
    "    print(\"  Please ensure Cells 1 and 5 (SIFT version) were run successfully IN THIS KERNEL SESSION.\")\n",
    "    print(\"\\nCannot proceed with timing.\")\n",
    "else:\n",
    "    # --- All checks passed, proceed with timing logic ---\n",
    "    print(\"\\n--- DEBUG: Pre-requisite checks passed. Proceeding with timing logic ---\")\n",
    "    # Use the variables confirmed to be in the local scope\n",
    "    sift = locals()['sift']\n",
    "    superglue = locals()['superglue']\n",
    "    superglue_config = locals()['superglue_config']\n",
    "    device = locals()['device']\n",
    "    convert_to_relative_center_coords = locals()['convert_to_relative_center_coords']\n",
    "\n",
    "    try:\n",
    "        # 1. Get list of valid image pairs\n",
    "        if not QUERY_DIR.is_dir() or not REF_DIR.is_dir():\n",
    "             raise FileNotFoundError(f\"Query ({QUERY_DIR}) or Reference ({REF_DIR}) image directory not found.\")\n",
    "\n",
    "        all_query_files = sorted([\n",
    "            f for f in QUERY_DIR.iterdir()\n",
    "            if f.is_file() and not f.name.startswith('.') and f.suffix.lower() == '.png'\n",
    "        ])\n",
    "        valid_pairs = [q for q in all_query_files if (REF_DIR / q.name).exists()]\n",
    "\n",
    "        if not valid_pairs:\n",
    "             print(\"No valid image pairs found in the dataset to perform timing.\")\n",
    "             num_to_process = 0\n",
    "        else:\n",
    "             num_to_process = min(len(valid_pairs), NUM_SAMPLES_FOR_TIMING)\n",
    "\n",
    "        if num_to_process > 0:\n",
    "            # 2. Select random sample\n",
    "            selected_files = random.sample(valid_pairs, num_to_process)\n",
    "            print(f\"Selected {num_to_process} files for timing:\")\n",
    "            for f in selected_files: print(f\"  - {f.name}\")\n",
    "\n",
    "            # 3. Run predictions and time\n",
    "            start_time = time.time()\n",
    "            processed_count = 0\n",
    "            prediction_times = []\n",
    "\n",
    "            for query_path in selected_files:\n",
    "                filename = query_path.name\n",
    "                ref_path = REF_DIR / filename\n",
    "                pair_start_time = time.time()\n",
    "\n",
    "                try:\n",
    "                    # --- Core Prediction Logic (SIFT Version) ---\n",
    "                    # a) Load Images (Grayscale)\n",
    "                    img0_gray = cv2.imread(str(query_path), cv2.IMREAD_GRAYSCALE)\n",
    "                    img1_gray = cv2.imread(str(ref_path), cv2.IMREAD_GRAYSCALE)\n",
    "                    if img0_gray is None or img1_gray is None:\n",
    "                        print(f\"  Skipping {filename}: Grayscale image loading error.\")\n",
    "                        continue\n",
    "                    query_h, query_w = img0_gray.shape[:2]\n",
    "                    ref_h, ref_w = img1_gray.shape[:2]\n",
    "\n",
    "                    # b) SIFT Feature Extraction\n",
    "                    kp0_sift, desc0_sift = sift.detectAndCompute(img0_gray, None)\n",
    "                    kp1_sift, desc1_sift = sift.detectAndCompute(img1_gray, None)\n",
    "                    if desc0_sift is None or desc1_sift is None or len(kp0_sift) == 0 or len(kp1_sift) == 0:\n",
    "                         print(f\"  Skipping {filename}: SIFT found no keypoints/descriptors.\")\n",
    "                         continue\n",
    "\n",
    "                    # c) Prepare data for SuperGlue (Match Cell 6 Logic)\n",
    "                    kpts0 = np.array([kp.pt for kp in kp0_sift], dtype=np.float32)\n",
    "                    kpts1 = np.array([kp.pt for kp in kp1_sift], dtype=np.float32)\n",
    "                    scores0 = np.array([kp.response for kp in kp0_sift], dtype=np.float32)\n",
    "                    scores1 = np.array([kp.response for kp in kp1_sift], dtype=np.float32)\n",
    "                    # Use 1.0 if response is 0? Or normalize? Keep response for now.\n",
    "                    # scores0 = np.maximum(scores0, 1e-6) # Avoid zero scores if they cause issues\n",
    "                    # scores1 = np.maximum(scores1, 1e-6)\n",
    "\n",
    "                    pred_input = {\n",
    "                        'keypoints0': torch.from_numpy(kpts0).unsqueeze(0).to(device),\n",
    "                        'keypoints1': torch.from_numpy(kpts1).unsqueeze(0).to(device),\n",
    "                        'descriptors0': torch.from_numpy(desc0_sift.T).unsqueeze(0).to(device),\n",
    "                        'descriptors1': torch.from_numpy(desc1_sift.T).unsqueeze(0).to(device),\n",
    "                        'scores0': torch.from_numpy(scores0).unsqueeze(0).to(device),\n",
    "                        'scores1': torch.from_numpy(scores1).unsqueeze(0).to(device),\n",
    "                        'image_size0': torch.tensor([query_h, query_w], dtype=torch.float32, device=device).unsqueeze(0),\n",
    "                        'image_size1': torch.tensor([ref_h, ref_w], dtype=torch.float32, device=device).unsqueeze(0)\n",
    "                        # Add 'image0'/'image1' tensors if the model requires them\n",
    "                    }\n",
    "\n",
    "                    # d) SuperGlue Matching\n",
    "                    with torch.no_grad():\n",
    "                        pred = superglue(pred_input)\n",
    "\n",
    "                    # e) Extract Matches & Confidence\n",
    "                    matches0 = pred.get('matches0', [None])[0] # Handle missing key + batch dim\n",
    "                    match_conf = pred.get('matching_scores0', [None])[0]\n",
    "                    if matches0 is None or match_conf is None:\n",
    "                         print(f\"  Skipping {filename}: SuperGlue output format unexpected.\")\n",
    "                         continue\n",
    "                    matches0 = matches0.cpu().numpy()\n",
    "                    match_conf = match_conf.cpu().numpy()\n",
    "\n",
    "                    # f) Filter Matches\n",
    "                    valid_match_mask = (matches0 > -1) & (match_conf > superglue_config['match_threshold'])\n",
    "                    match_indices0 = np.where(valid_match_mask)[0]\n",
    "                    match_indices1 = matches0[valid_match_mask]\n",
    "                    mkpts0 = kpts0[match_indices0]\n",
    "                    mkpts1 = kpts1[match_indices1]\n",
    "\n",
    "                    # g) Estimate Transformation\n",
    "                    min_req_points = 3\n",
    "                    if len(mkpts0) < min_req_points:\n",
    "                         print(f\"  Skipping {filename}: Not enough confident matches ({len(mkpts0)} < {min_req_points}).\")\n",
    "                         continue\n",
    "                    M, mask = cv2.estimateAffine2D(np.float32(mkpts0), np.float32(mkpts1), method=cv2.RANSAC, ransacReprojThreshold=5.0)\n",
    "\n",
    "                    # h) Check RANSAC & Decompose\n",
    "                    estimation_succeeded = False\n",
    "                    pred_angle = None\n",
    "                    trans_px_tl = None\n",
    "                    if M is not None:\n",
    "                        num_inliers = np.sum(mask) if mask is not None else 0\n",
    "                        if num_inliers >= min_req_points:\n",
    "                            estimation_succeeded = True\n",
    "                            tx, ty = M[0, 2], M[1, 2]\n",
    "                            trans_px_tl = (tx, ty)\n",
    "                            angle_rad = math.atan2(M[1, 0], M[0, 0])\n",
    "                            pred_angle = np.degrees(angle_rad) % 360\n",
    "                        else:\n",
    "                             print(f\"  Skipping {filename}: RANSAC found only {num_inliers} inliers.\")\n",
    "                    else:\n",
    "                         print(f\"  Skipping {filename}: estimateAffine2D failed.\")\n",
    "\n",
    "                    if not estimation_succeeded:\n",
    "                         continue\n",
    "\n",
    "                    # i) Convert Coordinates\n",
    "                    pred_x, pred_y = convert_to_relative_center_coords(\n",
    "                        trans_px_tl, pred_angle, (query_h, query_w), (ref_h, ref_w)\n",
    "                    )\n",
    "                    # --- End Core Prediction Logic ---\n",
    "\n",
    "                    # Success for this pair\n",
    "                    pair_end_time = time.time()\n",
    "                    prediction_times.append(pair_end_time - pair_start_time)\n",
    "                    processed_count += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  ERROR processing {filename} during timing loop:\")\n",
    "                    print(traceback.format_exc())\n",
    "\n",
    "            end_time = time.time()\n",
    "\n",
    "            # 4. Calculate and report times\n",
    "            total_wall_time = end_time - start_time\n",
    "            if processed_count > 0:\n",
    "                 total_prediction_time = sum(prediction_times)\n",
    "                 average_time = total_prediction_time / processed_count\n",
    "                 print(f\"\\n--- Timing Results (SIFT Version) ---\")\n",
    "                 print(f\"Successfully processed {processed_count} out of {num_to_process} selected pairs.\")\n",
    "                 print(f\"Total prediction time (sum of successful pairs): {total_prediction_time:.3f} seconds\")\n",
    "                 print(f\"Average prediction time per successful pair:   {average_time:.3f} seconds\")\n",
    "                 print(f\"Total wall time for {num_to_process} attempts: {total_wall_time:.3f} seconds\")\n",
    "            else:\n",
    "                 print(\"\\nNo pairs were successfully processed during timing.\")\n",
    "                 print(f\"Total wall time for {num_to_process} attempts: {total_wall_time:.3f} seconds\")\n",
    "\n",
    "    except FileNotFoundError as fnf:\n",
    "        print(f\"ERROR during file operations: {fnf}\")\n",
    "    except NameError as ne:\n",
    "         print(f\"UNEXPECTED ERROR: A required variable is not defined ({ne}).\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred OUTSIDE the timing loop:\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "print(\"\\n--- End of Cell 10 execution ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b9bbae-1cdb-4064-af56-c441d6854331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0907ad51-3e09-4c40-b612-663875fc674e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c05d14-9ed0-4e9a-8b75-9ef58533acdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491cac68-2e3c-4ce8-b100-663153796a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
